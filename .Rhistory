R2_simple
par(mar = c(2, 2, 2, 2))
plot(simple_linFit, pch=23 ,bg='orange',cex=2)
benchFit <- lm(log(Price) ~ 1, data=AirbnbTrain)
pred_bench <- exp(predict(benchFit, newdata=AirbnbTest))
#MSE comparison: my model vs benchmark
MSE_simple=sqrt(mean((pred_simple - log(AirbnbTest$Price))^2))
MSE_bench= sqrt(mean((pred_bench - log(AirbnbTest$Price))^2))
MSE_simple
MSE_bench
AirbnbTest$Superhost<-as.numeric(as.logical(AirbnbTest$Superhost))
# Store the response variable
Y <- log(AirbnbTrain$Price)
# Variables to add
variables_to_add <- names(AirbnbTrain)[-1]
# Create an empty data frame to store models and MSE
mse_df <- data.frame(MSE = numeric(length(variables_to_add)), Variables = character(length(variables_to_add)), stringsAsFactors = FALSE)
models <- list()
# Fit models and calculate MSE
for (i in seq_along(variables_to_add)) {
formula <- as.formula(paste("Y ~ ", paste(variables_to_add[1:i], collapse = " + ")))
model <- lm(formula, data = AirbnbTrain)
# Store the model
models[[i]] <- model
# Predict on the test set
pred <- exp(predict(model, newdata = AirbnbTest))
# Calculate MSE
mse <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
# Store MSE and variables in the data frame
mse_df[i, "MSE"] <- mse
mse_df[i, "Variables"] <- paste(variables_to_add[1:i], collapse = ", ")
}
# Add MSE for the benchmark model
mse_df[length(mse_df), c("MSE", "Variables")] <- c(MSE_bench, "Benchmark Model")
# Find the model with the lowest MSE
best_model_index <- which.min(mse_df$MSE)
best_model <- models[[best_model_index]]
# Print results
cat("Best model includes variables:", mse_df$Variables[best_model_index], "\n")
cat("MSE of the best model:", mse_df$MSE[best_model_index], "\n")
Y <- log(AirbnbTrain$Price)
variables_to_add= list("Normalised.Attraction.Index", "Normalised.Restraunt.Index", "Bedrooms", "Person.Capacity")
# Create an empty data frame to store models and MSE
mse_df <- data.frame(MSE = numeric(length(variables_to_add)), Variables = character(length(variables_to_add)), stringsAsFactors = FALSE)
models <- list()
# Fit models and calculate MSE
for (i in seq_along(variables_to_add)) {
formula <- as.formula(paste("Y ~ ", paste(variables_to_add[1:i], collapse = " + ")))
model <- lm(formula, data = AirbnbTrain)
# Store the model
models[[i]] <- model
# Predict on the test set
pred <- exp(predict(model, newdata = AirbnbTest))
# Calculate MSE
mse <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
# Store MSE and variables in the data frame
mse_df[i, "MSE"] <- mse
mse_df[i, "Variables"] <- paste(variables_to_add[1:i], collapse = ", ")
}
# Find the model with the lowest MSE
best_model_index <- which.min(mse_df$MSE)
best_model <- models[[best_model_index]]
# Print results
cat("Best model includes variables:", mse_df$Variables[best_model_index], "\n")
cat("MSE of the best model:", mse_df$MSE[best_model_index], "\n")
Y <- log(AirbnbTrain$Price)
variables_to_add= list("Normalised.Attraction.Index", "Normalised.Restraunt.Index", "Multiple.Rooms", "City.Center..km.", "Metro.Distance..km.", "Superhost")
# Create an empty data frame to store models and MSE
mse_df <- data.frame(MSE = numeric(length(variables_to_add)), Variables = character(length(variables_to_add)), stringsAsFactors = FALSE)
models <- list()
# Fit models and calculate MSE
for (i in seq_along(variables_to_add)) {
formula <- as.formula(paste("Y ~ ", paste(variables_to_add[1:i], collapse = " + ")))
model <- lm(formula, data = AirbnbTrain)
# Store the model
models[[i]] <- model
# Predict on the test set
pred <- exp(predict(model, newdata = AirbnbTest))
# Calculate MSE
mse <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
# Store MSE and variables in the data frame
mse_df[i, "MSE"] <- mse
mse_df[i, "Variables"] <- paste(variables_to_add[1:i], collapse = ", ")
}
# Find the model with the lowest MSE
best_model_index <- which.min(mse_df$MSE)
best_model <- models[[best_model_index]]
# Print results
cat("Best model includes variables:", mse_df$Variables[best_model_index], "\n")
cat("MSE of the best model:", mse_df$MSE[best_model_index], "\n")
best_linFit <- lm(log(Price) ~ Multiple.Rooms*(Normalised.Attraction.Index + Normalised.Restraunt.Index)^2 , data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(best_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_best <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_best
complex_linFit <- lm(log(Price) ~ Day , data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
day_linFit <- lm(log(Price) ~  Day, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(day_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_day <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_day
variables_to_add <- names(AirbnbTrain)[-1]
variables_to_add
complex_linFit <- lm(log(Price) ~ Room.Type , data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Person.Capacity , data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Person.Capacity , data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Superhost, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Multiple.Rooms, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Business, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Cleanliness.Rating, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Guest.Satisfaction, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Bedrooms, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_complex <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_complex
complex_linFit <- lm(log(Price) ~ Bedrooms, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_Bedrooms <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_Bedrooms
day_linFit <- lm(log(Price) ~  Day, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(day_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_day <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_day
variables_to_add <- names(AirbnbTrain)
variables_to_add
complex_linFit <- lm(log(Price) ~ City.Center..km., data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_Bedrooms <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_Bedrooms
complex_linFit <- lm(log(Price) ~ Bedrooms, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(complex_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_Bedrooms <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_Bedrooms
View(Airbnb)
day_linFit <- lm(log(Price) ~  Day, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(day_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_day <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_day
variables_to_add <- names(AirbnbTrain)
variables_to_add
View(day_linFit)
day_linFit
summary(day_linFit)
day_linFit <- lm(log(Price) ~  City, data=AirbnbTrain)
# Predict on the test set
pred <- exp(predict(day_linFit, newdata = AirbnbTest))
# Calculate MSE
MSE_day <- sqrt(mean((pred - log(AirbnbTest$Price))^2))
MSE_day
variables_to_add <- names(AirbnbTrain)
variables_to_add
summary(day_linFit)
# Include the library OpenImageR that is required to read the images
library(OpenImageR)
read_images <- function(lista_archivos){
# INPUT
# file_list - a list with all the paths of the images
# OUTPUT
# a list with all the data of the images (each item of the list corresponds to one image)
# Create an empty list to store data of the images
data_images <- list()
i=1
# Loop to read every image and store its data in the list
for (archivo in lista_archivos) {
data_image = readImage(archivo)
data_images[[i]] <- data_image
i=i + 1
}
return(data_images)
}
transform_data <- function(image_list){
# INPUT
# image_list - a list with the data of every image (this was obtained using read_images)
# OUTPUT
# pic_matrix - a matrix in which every row contains the data of one image
#              dimensions must be 108000 columns and as many rows as instances
# Initialize an empty pic_matrix with the right size (right number of columns)
pic_matrix <- matrix(nrow = 0, ncol = 108000)  # Must have 108000 columns
# Loop to transform the data of every image into a row and adds it to the pic_matrix
for (i in seq_along(image_list)) {
pic <- image_list[[i]]
new_row <- t(as.vector(pic))
pic_matrix <- rbind(pic_matrix, new_row)
# Verifying that the necessary matrix has the correct dimensions
#print(dim(pic_matrix))
}
return(pic_matrix)
}
split_train_test <- function(files) {
# Function to separate between test1, tes2, and train sets
# INPUT
# files - a list with the paths of the images
# OUTPUT
# a dataframe with threee columns:
#      - the path of each image
#      - the label/identifier of the image
#      - the set it belongs (it can be: train, test1 or test2)
#To select people randomly but in the same way in every execution of the code
set.seed(42)
# Extract label from every image
images <- c()
identifiers <- c()
for (image in files) {
if (substr(image, nchar(image) - 3 + 1, nchar(image)) == 'jpg') {
images <- c(images, image)
label <- gsub(".*?([0-9]+).*", "\\1", image) #1 refers to first
identifiers <- c(identifiers, as.numeric(label)) #there should be 25 ids
}
}
# Set up the dataframe with columns file and target
df <- data.frame(images, as.factor(identifiers))
names(df) <- c('file', 'target')
# Randomly select 4 identifiers to exclude from training
set.seed(42)
excluded_identifiers <- sample(unique(df$target), 4)
# Exclude the selected identifiers from the training set
df_train_validation <- df[!df$target %in% excluded_identifiers,]
# Randomly select 5 images for training and 1 for testing for each remaining identifier
# Add this images to the dataset 'train' and 'test1'
df_train_validation <- df_train_validation %>%
group_by(target) %>%
mutate(split = sample(c(rep('train', 5), 'test1'), size = n())) %>% #5 IMAGES TO TRAIN, 1 to test
ungroup()
# Add the excluded identifiers to the 'test2' set
df_test <- df[df$target %in% excluded_identifiers,]
df_test$split <- 'test2'
# Combine the datasets
split_df <- rbind(df_train_validation, df_test)
return(as.data.frame(split_df))
}
# Include the library OpenImageR that is required to read the images
library(OpenImageR)
read_images <- function(lista_archivos){
# INPUT
# file_list - a list with all the paths of the images
# OUTPUT
# a list with all the data of the images (each item of the list corresponds to one image)
# Create an empty list to store data of the images
data_images <- list()
i=1
# Loop to read every image and store its data in the list
for (archivo in lista_archivos) {
data_image = readImage(archivo)
data_images[[i]] <- data_image
i=i + 1
}
return(data_images)
}
transform_data <- function(image_list){
# INPUT
# image_list - a list with the data of every image (this was obtained using read_images)
# OUTPUT
# pic_matrix - a matrix in which every row contains the data of one image
#              dimensions must be 108000 columns and as many rows as instances
# Initialize an empty pic_matrix with the right size (right number of columns)
pic_matrix <- matrix(nrow = 0, ncol = 108000)  # Must have 108000 columns
# Loop to transform the data of every image into a row and adds it to the pic_matrix
for (i in seq_along(image_list)) {
pic <- image_list[[i]]
new_row <- t(as.vector(pic))
pic_matrix <- rbind(pic_matrix, new_row)
# Verifying that the necessary matrix has the correct dimensions
#print(dim(pic_matrix))
}
return(pic_matrix)
}
split_train_test <- function(files) {
# Function to separate between test1, tes2, and train sets
# INPUT
# files - a list with the paths of the images
# OUTPUT
# a dataframe with threee columns:
#      - the path of each image
#      - the label/identifier of the image
#      - the set it belongs (it can be: train, test1 or test2)
#To select people randomly but in the same way in every execution of the code
set.seed(42)
# Extract label from every image
images <- c()
identifiers <- c()
for (image in files) {
if (substr(image, nchar(image) - 3 + 1, nchar(image)) == 'jpg') {
images <- c(images, image)
label <- gsub(".*?([0-9]+).*", "\\1", image) #1 refers to first
identifiers <- c(identifiers, as.numeric(label)) #there should be 25 ids
}
}
# Set up the dataframe with columns file and target
df <- data.frame(images, as.factor(identifiers))
names(df) <- c('file', 'target')
# Randomly select 4 identifiers to exclude from training
set.seed(42)
excluded_identifiers <- sample(unique(df$target), 4)
# Exclude the selected identifiers from the training set
df_train_validation <- df[!df$target %in% excluded_identifiers,]
# Randomly select 5 images for training and 1 for testing for each remaining identifier
# Add this images to the dataset 'train' and 'test1'
df_train_validation <- df_train_validation %>%
group_by(target) %>%
mutate(split = sample(c(rep('train', 5), 'test1'), size = n())) %>% #5 IMAGES TO TRAIN, 1 to test
ungroup()
# Add the excluded identifiers to the 'test2' set
df_test <- df[df$target %in% excluded_identifiers,]
df_test$split <- 'test2'
# Combine the datasets
split_df <- rbind(df_train_validation, df_test)
return(as.data.frame(split_df))
}
pca <- function(data, perc) {
# INPUT
# data - a matrix that contains the data to which we must apply the PCA (a set of observations)
# perc - a number that determines the percentage of variance that is wanted to be kept, with this parameter it is decided the number of principal componenets that are going to be kept
# OUTPUT
# result - a list that contains the following elements:
# mean - a vector that contains the mean of every column (this is useful to center the data)
# P - the rotation matrix (this is the matrix we must multiply our data to obtain the data reduced with PCA)
# D - a vector that contains the variance explained with every new eigenvector that is added
# reduced_data - the data with dimensionality reduction (that is having applied matrix P)
# Calculate the mean of the observations
mean_vec <- colMeans(data)
# Center the data by subtracting the mean (and we have to decide whether if we scale or not)
centered_data <- scale(data, center = mean_vec, scale = F) #cambiar centrer = T y ver si sale igual
# Compute the covariance matrix
cov_matrix <- cov(t(centered_data))
#From now on, we perform everything with the short form of the data matrix (as h<<P).
# Perform eigenvalue decomposition for the short
eigen_result <- eigen(cov_matrix) #is the short
# Extract eigenvectors (P) and eigenvalues (e_values)
e_values <- eigen_result$values #as P will be calculated using the shot and the eigenvalues of the long and the short are the same, we direclty calculate them with the short
P_short <- eigen_result$vectors #this cannot be calculated like this as data is too large (36000*36000) so instead we use the short (n x n) (n - number of instances in the data)
# Percentage of the variance retaining by the PCs
D<-cumsum(e_values)/sum(e_values) # vector length n
# Find the index of the first term in the vector D that retains the percentage of variance desired
index <- which(D >= perc)[1]
# Retain only the elements until that index and rewrite the vector D and the matrix P until that index
D <- D[1:index] # vector of length m (m<n or m=n)
P_short <- P_short[,1:index] # matrix dim n * m
#Now we calculate the eigenvectors of the long matrix
#to do this, we need the eigenvectors of the short and data
#When applying the P eigenvectors
P <- t(centered_data)%*%P_short #dim(P) 108000 * m
reduced_data<-centered_data%*% P # dim(reduced_data) n * m
# Return mean, eigenvectors (matrix P), and variance (matrix D) of the set of observations
result <- list(mean = mean_vec, P = P, D = D, reduced_data= reduced_data)
return(result)
}
our_knn_multiple = function(data, tests, target, friends = 3, threshold=40, metric= 'euclidean') {
# INPUT
# data - a matrix with the training data (excluding the label)
# test - a matrix with the test data (the data we want to predict, without the label)
# target - a vector with the labels for the training data (same number of rows as the data matrix)
# friends - the number of kneighbours to apply the algorithm
# threshold - the maximum distance for which to consider that the new input belongs to the dataset
# metric - the method to compute the distance for the classification
# OUTPUT
# predictions - a list with the predicted classes per each test instance (same number of rows as test matrix)
predictions = list()
for (i in 1:nrow(tests)) {
test = tests[i, , drop = FALSE]
aux = rbind(data, test)
distances = as.matrix(dist(aux))
ndata = nrow(data)
distances = distances[ndata + 1, 1:ndata]
if (min(distances)>threshold) {
# if the person in the image is not in the training dataset, 0
predicted_class= 0
}
else{
ind = sort(distances, index.return = TRUE)
idx = ind$ix[1:friends]
neighbors = data[idx,]
neighbors_class = target[idx]
tb = table(neighbors_class)
predicted_class = names(tb)[which.max(tb)]
}
predictions[[i]] = predicted_class
}
return(predictions)
}
classifier <- function(df_train_data, df_test_data,PCAopt,k=3,thres=40,metric='manhattan') {
# INPUT
# df_train_data - the data (without the label) of the training set (it is a matrix)
# df_test_data - the data (without the label) of the test set (it is a matrix)
# PCAopt - binary value 1 if we want to apply PCA, 0 if we do not want to apply PCA
# k - number of neighbours for the KNN method
# thres - threshold value to determine whether a new image belongs to the dataset or not
# OUTPUT
# it returns the output of the knn applied
#1. Read the files from the dataframe
images_train = read_images(df_train_data$file)
images_test = read_images(df_test_data$file)
#1. Transform the data
train_matrix = transform_data(images_train)
test_matrix = transform_data(images_test)
#print('----------------')
#print(dim(train_matrix))
#print(dim(test_matrix))
#2. Apply KNN
if (PCAopt == TRUE) {
#2.1. Apply the PCA function only to the training
pca_values = pca(train_matrix)
P= pca_values$P
means = pca_values$mean
train_PCA =  pca_values$reduced_data #train data having used PCA to reduce dimensionality
D = pca_values$D
#2.2. KNN with PCA
#First, we select the data that will be used for KNN.
#The training set is already transformed in the previous PCA function.
datos_train = data.frame(x = train_PCA[,1], #taking the two first components of train_PCA
y = train_PCA[,2])
#The testing set needs to be transformed with the eigenvectors and the mean from
#the training set after applying PCA.
centered_data_test <- scale(test_matrix, center = means, scale = F)
print('-------------')
print(dim(centered_data_test))
print(dim(P))
#When applying the P eigenvectors
test_PCA <- centered_data_test %*% P
datos_test = data.frame(x = test_PCA[,1], #taking the two first components of test_PCA
y = test_PCA[,2])
knn_applied <- our_knn_multiple(datos_train, datos_test, df_train_data$target, friends=k, thres)
}
else{
#2.3. KNN without PCA
knn_applied <- our_knn_multiple(train_matrix, test_matrix, df_train_data$target, friends=k, thres)
}
#3. Accuracy from the predictions
#knn_applied$predicted == df_test_data$target
return(knn_applied)
}
accuracy <- function(prediction, target, test_type ){
# INPUT
# prediction - a ordered list with the predictions of the model
# target - a ordered list with the actual labels of the data
# test_type - a ordered list with the set that every instance belongs to (test1 or test2)
# OUTPUT
# it returns a list with two accuracies:
# accuracy_belong: it is the accuracy of the model to predict whether an instance belongs or not to the dataset
# accuracy_target: it is the accuracy of the model to predict the correct category of the instance
corrects_belong= 0
corrects_target=0
for (i in seq_along(prediction)){
if ((prediction[i] == 0 & test_type[i]=='test2') | (prediction[i] != 0 & test_type[i]=='test1')){
corrects_belong = corrects_belong + 1
if(prediction[i]== target[i]){
corrects_target= corrects_target + 1
}
}
}
accuracy_belong= corrects_belong/ length(prediction)
accuracy_target = corrects_target/ length(prediction)
return(list(accuracy_belong, accuracy_target))
}
